---
title: Conteúdo Otimizado
description: Conteúdo selecionado com 210 links e 1 imagens preservados
category: security
---

# Awesome-LLM [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

[](https://raw.githubusercontent.com/Hannibal046/Awesome-LLM/main/resources/image8.gif)

Modelos de linguagem grandes (LLM) tomaram a comunidade ~~NLP~ A comunidade da AI, o mundo inteiro, por tempestade. Aqui está uma lista de artigos sobre grandes modelos de linguagem, especialmente relacionados ao ChatGPT. Ele também contém frameworks para treinamento LLM, ferramentas para implantar LLM, cursos e tutoriais sobre LLM e todos os postos de controle LLM disponíveis publicamente e APIs.

# # Trending LLM Projects

- [TinyZero](https://github.com/Jiayi-Pan/TinyZero) - Reprodução limpa, mínima e acessível de DeepSeek R1-Zero
- [open-r1](https://github.com/huggingface/open-r1) - Reprodução totalmente aberta de DeepSeek-R1
- [DeepSeek-R1] (https://github.com/deepseek-ai/DeepSeek-R1) - Modelos de raciocínio de primeira geração da DeepSeek.
- [Qwen2.5-Max](https://qwenlm.github.io/blog/qwen2.5-max/) - Explorando a Inteligência do Modelo MoE em larga escala.
- [OpenAI o3-mini](https://openai.com/index/openai-o3-mini/) - Impulsionando a fronteira do raciocínio econômico.
- [DeepSeek-V3] (https://github.com/deepseek-ai/DeepSeek-V3) - Primeiro modelo de nível GPT-4o de código aberto.
- [Kimi-K2](https://github.com/MoonshotAI/Kimi-K2) - Modelo de linguagem MoE com parâmetros 32B ativos e 1T total.

# # Tabela de Conteúdo
- [Awesome-LLM ] (#awesome-llm-)
- [Milestone Papers] (#Milestone-papers)
- [Outros papéis] (#outros papéis)
- [LLM Leaderboard] (#llm-leaderboard)
- [Abrir LLM] (#open-llm)
- [Dados LLM] (# dados llm)
- [Avaliação LLM] (# avaliação llm)
[LLM Training Framework] (#llm-training-frameworks)
- [LLM inferência] (#llm inferência)
- [LLM Aplicações] (#llm aplicações)
- [LLM Tutoriais e Cursos] (#llm-tutorials-and-courses)
- [LLM Books] (#llm-books)
Boa ideia sobre o LLM.
- [Diversos] (# diversos)

# # Milestone Papers

<detalhes>

<Summary> artigos de referência </summary>

Data Palavras-chave do Instituto
-----------::---------------------:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

(https://arxiv.org/pdf/1706.03762.pdf) □
* 2018-06 * GPT 1.0 O OpenAI [Melhorando a compreensão linguística por meio do pré-treinamento genético](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improveing.pdf) □
(https://aclanthology.org/N19-1423.pdf) □
* 2019-02 * GPT 2.0 O OpenAI (https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
* 2019-09 * Megatron-LM * NVIDIA Modelo Paralelismo](https://arxiv.org/pdf/1909.08053.pdf) □
(https://jmlr.org/papers/v21/20-074.html) □
(https://arxiv.org/pdf/1910.02054.pdf) □
. . 2020-01 . . . . . . . . . (https://arxiv.org/pdf/2001.08361.pdf) □
.2020-05 . 3.0 □ OpenAI [Modelos de línguas são alunos com poucas imagens](https://papers.nips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf) □

(https://arxiv.org/pdf/2101.03961.pdf) □
(https://arxiv.org/pdf/2107.03374.pdf) □
Os modelos da Fundação são os modelos de Stanford (https://arxiv.org/pdf/2108.07258.pdf) □
(https://openreview.net/forum?id=geZrGCozdqR) □
2021-10 T0 Face et al. [Multitask Prompted Training Activa a Generalização da Tarefa Zero-Shot](https://arxiv.org/abs/2110.08207) □
(https://arxiv.org/pdf/2112.0695.pdf) □
(https://www.semanticscholar.org/paper/WebGPT%3A-Browser-assisted-question-reswering- with-Nakano-Hilton/2f3efe44083af91cef562c1a3451eee2f8601d22) □
(https://www.deepmind.com/publications/imelhoring-language-models-by-retrieving- from-trillions-of-tokens) □
(https://arxiv.org/pdf/2112.11446.pdf) □

(https://arxiv.org/pdf/2201.11903.pdf) □
(https://arxiv.org/pdf/2201.08239.pdf) □
(https://arxiv.org/abs/2206.14858) □
(https://arxiv.org/pdf/2201.11990.pdf) □
(https://arxiv.org/pdf/2203.02155.pdf) □
(https://arxiv.org/pdf/2204.0231.pdf) □
(https://arxiv.org/pdf/223.15556) □
(https://arxiv.org/pdf/2205.01068.pdf) □
* 2022-05 * UL2 * Google * [Unifying Language Learning Paradigms] (https://arxiv.org/abs/2205.05131v1) □

Emergentes Habilidades do Google (https://openreview.net/pdf?id=yzkSU5zdwD) □
(https://github.com/google/BIG-bench) □
(https://arxiv.org/pdf/2206.06336.pdf) □
(https://arxiv.org/pdf/220.14375.pdf) □
(https://arxiv.org/pdf/2210.11416.pdf) □
(https://arxiv.org/pdf/2210.02414.pdf) □
(https://arxiv.org/pdf/2211.09110.pdf) □
(https://arxiv.org/pdf/2211.05100.pdf) □
(https://arxiv.org/pdf/2211.09085.pdf) □

(OPT-IML) Meta Aprender através da Lens of Generalization (https://arxiv.org/pdf/2212.12017) □
(https://arxiv.org/pdf/2301.13688.pdf) □
(https://research.facebook.com/publications/llama-open-and-effective-foundation-language models/) □
(https://arxiv.org/abs/2302.14045) □
(https://arxiv.org/abs/2303.06349) □
*Palm-e.github.io □
(https://openai.com/research/gpt-4) □
(https://arxiv.org/abs/2304.08485) □
(https://arxiv.org/abs/2304.01373) □

(https://arxiv.org/abs/2305.03047) □
* 2023-05 * PaLM 2 O Google (PaLM 2 Technical Report)(https://ai.google/static/documents/palm2techreport.pdf) □
(https://arxiv.org/abs/2305.13048)
(https://arxiv.org/pdf/2305.18290.pdf) □
(https://arxiv.org/pdf/2305.10601.pdf) □
(https://arxiv.org/pdf/2307.09288.pdf) □
* Mistral 7B [Mistral 7B](https://arxiv.org/pdf/2310.06825.pdf) □
(https://arxiv.org/pdf/2312.00752) □
(https://arxiv.org/abs/2405.04434) □

(https://arxiv.org/abs/2402.00838) □  
(https://arxiv.org/abs/2405.21060)  
2024-05 Llama3 Meta (https://arxiv.org/abs/2407.21783) □  
(https://arxiv.org/abs/2406.17557) □  
(https://arxiv.org/abs/2409.02060) □  
(https://arxiv.org/abs/2412.15115) □  
(https://arxiv.org/abs/2412.19437v1) □  
(https://arxiv.org/abs/2501.12948) □

</detalhes>

# Outros Documentos
> [!NOTA]
> Se você está interessado no campo da LLM, pode achar que a lista acima de documentos importantes é útil para explorar sua história e o estado da arte. No entanto, cada direção da LLM oferece um conjunto único de insights e contribuições, que são essenciais para entender o campo como um todo. Para uma lista detalhada de artigos em vários subcampos, consulte o seguinte link:

<detalhes>
< Resumo> Outros artigos </síntese>

- [Awesome-LLM-halucination](https://github.com/LuckyySTA/Awesome-LLM-halucination) - Lista de trabalhos sobre alucinações em LLMs. Compilação de estudos focados na detecção de alucinações em LLMs.
- [LLMsPracticalGuide](https://github.com/Mooler0410/LLMsPracticalGuide) - Uma lista de recursos para um guia prático sobre LLMs.
- [Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts) - Uma coleção de exemplos para serem utilizados com o modelo ChatGPT.
- [awesome-chatgpt-prompts-zh](https://github.com/PlexPt/awesome-chatgpt-prompts-zh) - Uma coleção em chinês de exemplos rápidos para uso com o modelo ChatGPT.
- [Awesome ChatGPT](https://github.com/humanloop/awesome-chatgpt) - Lista de recursos para o ChatGPT e GPT-3 da OpenAI.

- [Chain-of-Thoughts Papers] (https://github.com/Timothyxxx/Chain-of-ThoughtsPapers) - Uma tendência começa a partir de "Chain of Thought Prompting Elicis Raciocing in Large Language Models".
- [Awesome Deliberative Prompting] (https://github.com/logikon-ai/awesome-deliberative-prompting) - Como pedir aos LLMs que produzam raciocínios fiáveis e tomem decisões razoáveis.
- [Instruction-Tuning-Papers](https://github.com/SinclairCoder/Instruction-Tuning-Papers) - Uma tendência começa a partir de `Natrural-Instruction` (ACL 2022), `FLAN` (ICLR 2022) e `T0` (ICLR 2022).
- [Lista de Leitura LLM](https://github.com/loucofapple/Reading_groups/) - Uma lista de papéis e recursos de modelos de línguas grandes.
- [Reasoning using Language Models](https://github.com/atfortes/LM-Reasoning-Papers) - Recolha de artigos e recursos sobre Raciocínios utilizando Modelos de Linguagem.
(https://github.com/FranxYao/chain-of-thought-hub) - Medindo o desempenho de raciocínio dos LLMs
- [Awesome GPT](https://github.com/formulahendry/awesome-gpt) - Uma lista de projetos e recursos impressionantes relacionados com GPT, ChatGPT, OpenAI, LLM, e muito mais.
- [Awesome GPT-3](https://github.com/elyase/awesome-gpt3) - uma coleção de demos e artigos sobre a API [OpenAI GPT-3](https://openai.com/blog/openai-api/).
- [Awesome LLM Human Preference Datasets] (https://github.com/PolisAI/awesome-llm-human-preference-datessets) - uma coleção de conjuntos de dados de preferência humana para ajuste de instrução LLM, RLHF e avaliação.
- [RWKV-howto](https://github.com/Hannibal046/RWKV-howto) - possivelmente materiais úteis e tutorial para aprender RWKV.
- [ModeloEditandoPapers] (https://github.com/zjunlp/ModeloEditandoPapers) - Uma lista de papéis e recursos sobre a edição de modelos para modelos de línguas grandes.
- [Awesome LLM Security](https://github.com/corca-ai/awesome-llm-security) - Uma curadoria de ferramentas, documentos e projetos incríveis sobre a LLM Security.
- [Awesome-Aign-LLM-Human] (https://github.com/GaryYufei/AignLLMHumanSurvey) - Uma coleção de artigos e recursos sobre o alinhamento de grandes modelos de linguagem (LLMs) com humanos.
- [Awesome-Code-LLM] (https://github.com/huybery/Awesome-Code-LLM) Uma lista incrível e curadoria do melhor código-LLM para pesquisa.
- [Awesome-LLM-Compression] (https://github.com/HuangOwen/Awesome-LLM-Compression) - Impressionantes trabalhos e ferramentas de pesquisa de compressão LLM.
- [Awesome-LLM-Systems] (https://github.com/AmberLJC/LLMSys-PaperList) - Awesome LLM systems research papers.

- [awesome-llm-webapps] (https://github.com/snowfort-ai/awesome-llm-webapps) - Uma coleção de aplicativos web de código aberto, mantidos ativamente para aplicações LLM.
(https://github.com/llm-jp/awesome-japanês-llm) - 日本語LLM
- [Awesome-LLM-Healthcare] (https://github.com/mingze-yuan/Awesome-LLM-Healthcare) A lista de artigos da revisão sobre LLMs em medicina.
- [Awesome-LLM-Inference] (https://github.com/DefTruth/Awesome-LLM-Inference) - Uma lista com curadoria de Awesome LLM Inference Paper com códigos.
- [Awesome-LLM-3D](https://github.com/ActiveVisionLab/Awesome-LLM-3D) - Uma lista com curadoria do modelo multimodal de linguagem grande no mundo 3D, incluindo compreensão 3D, raciocínio, geração e agentes encarnados.
- [LLMDatahub](https://github.com/Zjh-819/LLMDataHub) - uma colecção de conjuntos de dados especificamente concebidos para a formação de chatbots, incluindo ligações, dimensão, linguagem, utilização e uma breve descrição de cada conjunto de dados
- [Awesome-Chinese-LLM] (https://github.com/HqWu-HITCS/Awesome-Chinese-LLM) - .

- [LLM4Opt](https://github.com/FeiLiu36/LLM4Opt) - A aplicação de modelos de linguagem grandes (LLMs) em várias tarefas de otimização (Opt) é um campo de pesquisa em crescimento. Esta é uma coleção de referências e artigos da LLM4Opt.

(https://github.com/Furyton/awesome-language-model-analysis) Esta lista de artigos foca na análise teórica ou empírica de modelos de linguagem, abordando temas como a dinâmica de aprendizado, a capacidade expressiva, a interpretabilidade, a generalização e outros tópicos interessantes.

</detalhes>

# # LLM Leaderboard
- [Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard) - uma plataforma de referência para grandes modelos de linguagem (LLMs) que apresenta batalhas anônimas e aleatórias de forma crowdsourced.
- [LiveBench] (https://livebench.ai/#/) - Um LLM desafiante, livre de contaminação Benchmark.
- [Open LLM Leaderboard] (https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard) - visa rastrear, classificar e avaliar LLMs e chatbots à medida que são lançados.
- [AlpacaEval](https://tatsu-lab.github.io/alpaca_eval/) - Um Avaliador Automático para Modelos de Linguagem Seguida por Instruções usando o pacote de benchmark Nous.
<detalhes>
<síntese> outras tabelas de classificação </síntese>

- [ACLUE](https://github.com/isen-zhang/ACLUE) - uma referência de avaliação centrada na compreensão da língua chinesa antiga.

- [BeHonest](https://gair-nlp.github.io/BeHonest/#leaderboard) - Um referencial pioneiro especificamente concebido para avaliar a honestidade em LLMs de forma abrangente.
- [Berkeley Function-Chaming Leaderboard] (https://gorilla.cs.berkeley.edu/leaderboard.html) - avalia a capacidade da LLM de chamar funções/ferramentas externas.
- [Chinese Large Model Leaderboard](https://github.com/jeinlee1991/chinese-llm-benchmark) - um benchmark orientado por especialistas para os chineses LLMs.
(https://rank.opencompass.org.cn) - O CompassRank dedica-se a explorar os modelos de linguagem e visual mais avançados, oferecendo uma referência de avaliação abrangente, objetiva e neutra para a indústria e pesquisa.
- [CompMix](https://qa.mpi-inf.mpg.de/compmix) - um método de avaliação de referência de QA que opera sobre uma mistura de fontes de entrada heterogêneas (KB, texto, tabelas, infoboxes).
- [DreamBench++](https://dreambenchplus.github.io/#leaderboard) - um benchmark para avaliar o desempenho de modelos de grande linguagem (LLMs) em várias tarefas relacionadas com a imaginação textual e visual.
- [FELM](https://hkust-nlp.github.io/felm) - uma meta-benchmark que avalia como os avaliadores de factualidade avaliam bem as saídas de modelos de linguagem de grande porte (LLMs).
- [InfiBench](https://infi-coder.github.io/infibench) - uma referência concebida para avaliar modelos de línguas de grande dimensão (LMLs) especificamente na sua capacidade de responder a questões relacionadas com a codificação no mundo real.
- [LawBench](https://lawbench.opencompass.org.cn/leaderboard) - um benchmark concebido para avaliar grandes modelos de linguagem no domínio jurídico.
- [LLMEval](http://llmeval.com) - centra-se na compreensão de como estes modelos funcionam em vários cenários e na análise de resultados numa perspectiva de interpretabilidade.
- [M3CoT](https://lightchen233.github.io/m3cot.github.io/leaderboard.html) - um benchmark que avalia grandes modelos de linguagem em uma variedade de tarefas de raciocínio multimodal, incluindo linguagem, ciências naturais e sociais, senso comum físico e social, raciocínio temporal, álgebra e geometria.
- [MathEval](https://matheval.ai) - uma plataforma abrangente de benchmarking projetada para avaliar as habilidades matemáticas de grandes modelos em 20 campos e quase 30.000 problemas matemáticos.

- [MixEval](https://mixeval.github.io/#leaderboard) - um benchmark dinâmico baseado na verdade-terra derivado de misturas de benchmark off-the-shelf, que avalia LLMs com uma classificação de modelo altamente capaz (ou seja, 0,96 de correlação com Chatbot Arena) enquanto executando localmente e rapidamente (6% do tempo e do custo de execução do MMLU).
- [MmedBench](https://henrychur.github.io/MultilingualMedQA) - um benchmark que avalia a capacidade dos modelos de grande linguagem em responder a perguntas médicas em vários idiomas.
- [MMToM-QA](https://chuanyangjin.com/mmtom-qa-leaderboard) - um benchmark multimodal de respostas de perguntas projetado para avaliar a capacidade cognitiva dos modelos de IA para entender crenças e objetivos humanos.
- [OlympicArena] (https://gair-nlp.github.io/OlympicArena/#leaderboard) - uma referência para avaliar modelos de IA em várias disciplinas acadêmicas, como matemática, física, química, biologia, e muito mais.
- [PubMedQA](https://pubmedqa.github.io) - uma referência biomédica para responder a perguntas relacionadas com a investigação, utilizando resumos PubMed.
- [SciBench](https://scibench-ucla.github.io/#leaderboard) - benchmark projetado para avaliar modelos de linguagem de grande porte (LLMs) na resolução de problemas científicos complexos, de nível universitário, de domínios como química, física e matemática.
- [SuperBench](https://fm.ai.tsinghua.edu.cn/superbench/#/leaderboard) - uma plataforma de referência concebida para avaliar modelos de linguagem de grande dimensão (LLMs) numa série de tarefas, particularmente centrada no seu desempenho em diferentes aspectos, como a compreensão da linguagem natural, o raciocínio e a generalização.
- [SuperLim](https://lab.kb.se/leaderboard/results) - um benchmark de compreensão da língua sueca que avalia modelos de processamento de linguagem natural (NLP) em várias tarefas, como análise de argumentação, similaridade semântica e envolvimento textual.
- [TAT-DQA](https://nextplus.github.io/TAT-DQA) - um conjunto de dados de resposta visual de documentos em larga escala (VQA) concebido para uma compreensão complexa dos documentos, especialmente em relatórios financeiros.
- [TAT-QA](https://nextplus.github.io/TAT-QA) - um benchmark de respostas a perguntas em larga escala centrado em dados financeiros do mundo real, integrando informações tabulares e textuais.
- [VisualWebArena](https://jykoh.com/vwa) - uma referência concebida para avaliar o desempenho de agentes web multimodais em tarefas realistas de base visual.

- [We-Math](https://we-math.github.io/#leaderboard) - um benchmark que avalia grandes modelos multimodais (LMMs) sobre sua capacidade de realizar raciocínio matemático semelhante ao humano.
- [WHOOPS!](https://whoops-benchmark.github.io) - um conjunto de dados de referência que testa a capacidade da IA de raciocinar sobre o senso comum visual através de imagens que desafiam as expectativas normais.

</detalhes>

# # Abra LLM
<detalhes>
< Resumo>DeepSeek</síntese>

- [DeepSeek-Math-7B](https://huggingface.co/colectionions/deepseek-ai/deepseek-math-65f2962739da11599e441681)
- [DeepSeek-Coder-1.3 .67 .7 .33B](https://huggingface.co/collections/deepseek-ai/deepseek-coder-65f295d7d8a0a29fe39b4ec4)
- [DeepSeek-VL-1.3%] (https://huggingface.co/colectionions/deepseek-ai/deepseek-vl-65f295948133d9cf92b706d3)
- [DeepSeek-MoE-16B](https://huggingface.co/collections/deepseek-ai/deepseek-moe-65f29679f5cf26fe063686bf)
- [DeepSeek-v2-236B-MoE](https://arxiv.org/abs/2405.04434)
- [DeepSeek-Coder-v2-16236B-MOE](https://github.com/deepseek-ai/DeepSeek-Coder-V2)
- [DeepSeek-V2.5](https://huggingface.co/deepseek-ai/DeepSeek-V2.5)
- [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3)
- [DeepSeek-R1](https://github.com/deepseek-ai/DeepSeek-R1)

</detalhes>
<detalhes>
< Resumo>Alibaba</síntese>

Claro! Aqui está o texto reescrito em português brasileiro, mantendo as especificações que você pediu:

- [Qwen-1,8B .7B .14B .72B](https://huggingface.co/colectionions/Qwen/qwen-65c0e50c3f1ab89cb8704144)
- [Qwen1.5-0.5B'1.8B'4B'7B'14B'32B'72B'110B'MoE-A2.7B](https://qwenlm.github.io/blog/qwen1.5/)
- [Qwen2-0.5B'1.5B'7B'57B-A14B-MoE'72B](https://qwenlm.github.io/blog/qwen2)
- [Qwen2.5-0.5B;1.5B;3B;7B;14B;32B;72B](https://qwenlm.github.io/blog/qwen2.5/)
- [CodeQwen1.5-7B](https://qwenlm.github.io/blog/codeqwen1.5/)
- [Qwen2.5-Coder-1,5B-7B-32B](https://qwenlm.github.io/blog/qwen2.5-coder/)
- [Qwen2-Math-1,5B-7B-72B](https://qwenlm.github.io/blog/qwen2-math/)
- [Qwen2.5-Math-1.5B7B2B](https://qwenlm.github.io/blog/qwen2.5-math/)
- [Qwen-VL-7B](https://huggingface.co/Qwen/Qwen-VL) (https://qwenlm.github.io/blog/qwen2-vl/)
- [Qwen2-Audio-7B](https://qwenlm.github.io/blog/qwen2-audio/)
- [Qwen2.5-VL-372B](https://qwenlm.github.io/blog/qwen2.5-vl/)
- [Qwen2.5-1M-7'14B](https://qwenlm.github.io/blog/qwen2.5-1m/)

</detalhes>

<detalhes>
< Resumo>Meta</síntese>

- [Llama 3, 2- 1- 3- 11- 90- B] (https://llama.meta.com/)
- [Llama 3.1- 8- 70- 405B] (https://llama.meta.com/)
- [Llama 3-8°70B](https://llama.meta.com/llama3/)
- [Llama 2-7 o 13 o 70 B] (https://llama.meta.com/llama2/)

- [Llama 1-7 o 13 o 33 o 65 B] (https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)
- [OPT-1.3'6.7'13'30'66B](https://arxiv.org/abs/220.0168)

</detalhes>

<detalhes>
< Resumo>AI mistral</síntese>

- [Codestral-7 o 22 B] (https://mistral.ai/news/codestral/)
- [Mistral-7B](https://mistral.ai/news/anuncing-mistral-7b/)
- [Mixtral-8x7B](https://mistral.ai/news/mixtral-of-experts/)
- [Mixtral-8x22B](https://mistral.ai/news/mixtral-8x22b/)

</detalhes>
<detalhes>
<Resumo>Google</síntese>

- [Gemma2-9 o27B](https://blog.google/technology/developers/google-gemma-2/)
- [Gemma-27B](https://blog.google/technology/developers/gemma-open-models/)
- [RecurrentGemma-2B](https://github.com/google-deepmind/recurrentgemma)
- [T5](https://arxiv.org/abs/1910.10683)

</detalhes>
<detalhes>
< Resumo>Apple</síntese>

- [OpenELM-1.1 o3B](https://huggingface.co/apple/OpenELM)

</detalhes>
<detalhes>
< Resumo>Microsoft</síntese>

- [Phi1-1.3B](https://huggingface.co/microsoft/phi-1)
- [Phi2-2.7B](https://huggingface.co/microsoft/phi-2)
- [Phi3-3.8 o7 o14B] (https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)

</detalhes>
<detalhes>
< Resumo> AllenAI</síntese>

- [OLMo-7B](https://huggingface.co/colectionions/allenai/olmo-suite-65aeaae8fe5b6b2122b46778)

</detalhes>
<detalhes>
< Resumo>xAI</síntese>

(https://x.ai/blog/grok-os)

</detalhes>
<detalhes>
< Resumo>Cohere</síntese>

- [Comando R-35B](https://huggingface.co/CohereForAI/c4ai-command-r-v01)

</detalhes>

<detalhes>
< Resumo>01-ai</síntese>

- [Yi-34B](https://huggingface.co/colectionions/01-ai/yi-2023-11-663f3f19119ff712e176720f)
- [Yi1.5-69-34B](https://huggingface.co/colectionions/01-ai/yi-15-2024-05-663f3ecab5f815a3eaca7ca8)
- [Yi-VL-6Bl34B](https://huggingface.co/colectionions/01-ai/yi-vl-663f55728538eae745769f3)

</detalhes>

<detalhes>
< Resumo>Baichuan</síntese>

- [Baichuan-7 o13B](https://huggingface.co/baichuan-inc)
- [Baichuan2-7-13B](https://huggingface.co/baichuan-inc)

</detalhes>

<detalhes>
< Resumo>Nvidia</síntese>

- [Nemotron-4-340B](https://huggingface.co/nvidia/Nemotron-4-340B-Instruct)

</detalhes>

<detalhes>
< Resumo>BLOOM</síntese>

(https://huggingface.co/bigscience/bloomz)

</detalhes>
<detalhes>
< Resumo> Zhipu AI</síntese>

- [GLM-26,10,13,70B](https://huggingface.co/THUDM)
- [CogVLM2-19B](https://huggingface.co/collections/THUDM/cogvlm2-6645f36a29948b67dc4eef75)

</detalhes>
<detalhes>
<síntese>OpenBMB</síntese>

- [MiniCPM-2B](https://huggingface.co/colectionions/openbmb/minicpm-2b-65d48bf958302b9fd25b698f)
- [OmniLLM-12B](https://huggingface.co/openbmb/OmniLMM-12B)
- [VisCPM-10B](https://huggingface.co/openbmb/VisCPM-Chat)
- [CPM-Bee-1'2'5'10B](https://huggingface.co/colectionions/openbmb/cpm-bee-65d491cc84fc9350d789361)

</detalhes>
<detalhes>
< Resumo>RWKV Fundação</síntese>

(https://huggingface.co/RWKV)minicpm-2b-65d48bf958302b9fd25b698f)

</detalhes>

<detalhes>
< Resumo> ElutherAI</síntese>

- [Pythia-1/4'2.8'6.9'12B](https://github.com/EleutherAI/pythia)

</detalhes>

<detalhes>
<síntese>IA de estabilidade</síntese>

- [StableLM-3B](https://huggingface.co/stabilityai/stablelm-3b-4e1t)
- [StableLM-v2-1.6B](https://huggingface.co/stabilityai/stablelm-2-1_6b)
- [StableLM-v2-12B](https://huggingface.co/stabilityai/stablelm-2-12b)
- [StableCode-3B](https://huggingface.co/collections/stabilityai/stable-code-64f9dfb4ebc8a1be0a3f7650)

</detalhes>
<detalhes>
<síntese>BigCode</síntese>

- [StarCoder- 13] (https://huggingface.co/collections/bigcode/%E2%AD% 90- starcoder- 64f9bd5740eb5daaeb81dbec)
- [StarCoder2-37-15B](https://huggingface.co/collections/bigcode/starcoder2-65de6da6e87db3383572be1a)

</detalhes>
<detalhes>
<síntese>DataBricks</síntese>

- [MPT-7B](https://www.databricks.com/blog/mpt-7b)
- [DBRX-132B-MoE](https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm)

</detalhes>
<detalhes>
< Resumo>Laboratório de IA de Shanghai</síntese>

- [InternLM2-1.8°7°20B](https://huggingface.co/colectionions/internlm/internlm2-65b0ce04970888799707893c)
- [InternLM-Math-7B-20B](https://huggingface.co/colectionions/internlm/internlm2-math-65b0ce88bf7d3327d0a5ad9f)
- [InternLM-XComposer2-1,807B](https://huggingface.co/colectionions/internlm/internlm-xcomposer2-65b3706bf5d76208998e7477)
- [InternVL-2'6'14'26] (https://huggingface.co/colectionions/OpenGVLab/internvl-65b92d6be81c86166ca0dde4)

</detalhes>
<detalhes>
< Resumo>I.A.

- [Moonlight-A3B](https://huggingface.co/colectionions/moonshotai/moonlight-a3b-67f67b029cecfdce34f4dc23)
- [Kimi-VL-A3B](https://huggingface.co/collections/moonshotai/kimi-vl-a3b-67f67b6ac91d3b03d382dd85)
- [Kimi-K2](https://huggingface.co/collections/moonshotai/kimi-k2-6871243b990f2af5ba60617d)

</detalhes>

# # LLM Dados
> Referência: [LLMDataHub](https://github.com/Zjh-819/LLMDataHub)

- [IBM data-prep-kit] (https://github.com/IBM/data-prep-kit) - Kit de ferramentas de código aberto para processamento de dados não estruturado eficiente com módulos pré-construídos e escalabilidade local para cluster.
- [Datatrove](https://github.com/huggingface/datatrove) - Libertando o processamento de dados da loucura de scripting, fornecendo um conjunto de blocos de processamento de pipeline personalizáveis para o diagnóstico de plataforma.
(https://github.com/DataEval/dingo) - Dingo: Uma ferramenta abrangente de avaliação da qualidade dos dados
- [FastDatasets] (https://github.com/ZhuLinsen/FastDatasets) - Uma poderosa ferramenta para criar conjuntos de dados de formação de alta qualidade para modelos de línguas grandes

# # Avaliação de LLM:
- [lm-avaliation-harness](https://github.com/EleutherAI/lm-avaliation-harness) - Um framework para avaliação de poucos resultados de modelos de linguagem.
- [lighteval](https://github.com/huggingface/lighteval) - um conjunto de avaliação LLM leve que o Hugging Face tem utilizado internamente.
- [simple-evals](https://github.com/openai/simple-evals) - Ferramentas de avaliação do OpenAI.

<detalhes>
<síntese>outros quadros de avaliação</síntese>

- [OLMO-eval](https://github.com/allenai/OLMo-Eval) - um repositório para avaliação de modelos de linguagem aberta.
- [MixEval] (https://github.com/Psycoy/MixEval) - Um conjunto de avaliação fiável, compatível com modelos de código aberto e proprietários, que apoiam o MixEval e outros parâmetros de referência.
- [HELM](https://github.com/stanford-crfm/helm) - Avaliação Holística dos Modelos de Linguagem (HELM), um quadro para aumentar a transparência dos modelos de linguagem.
- [instruct-eval] (https://github.com/declare-lab/instruct-eval) - Este repositório contém código para avaliar quantitativamente modelos de instrução sintonizados como Alpaca e Flan-T5 em tarefas realizadas.
- [Giskard](https://github.com/Giskard-AI/giskard) - Biblioteca de testes e avaliação para aplicações LLM, em particular RAGs
- [LangSmith](https://www.langchain.com/langsmith) - uma plataforma unificada da estrutura LangChain para: avaliação, colaboração HITL (Human In The Loop), registro e monitoramento de aplicações LLM.
- [Ragas](https://github.com/explodinggradients/ragas) - um framework que ajuda você a avaliar seus pipelines de geração aumentada de recuperação (RAG).

</detalhes>

# # Quadros de Treinamento LLM

- [Meta Lingua](https://github.com/facebookresearch/lingua) - uma base de código enxuta, eficiente e fácil de usar para pesquisar LLMs.
- [Litgpt](https://github.com/Lightning-AI/litgpt) - 20+ alto desempenho LLMs com receitas para pré-treinar, refinar e implantar em escala.

- [nanotron](https://github.com/huggingface/nanotron) - Formação minimalista de linguagem de grande porte modelo 3D-paralelismo.
- [DeepSpeed](https://github.com/microsoft/DeepSpeed) - DeepSpeed é uma biblioteca de otimização de aprendizagem profunda que torna o treinamento distribuído e inferência fácil, eficiente e eficaz.
- [Megatron-LM](https://github.com/NVIDIA/Megatron-LM) - Modelos de transformadores de formação contínua em escala.
- [torchtitan](https://github.com/pytorch/torchtitan) - Uma Biblioteca PyTorch nativa para treinamento de grandes modelos.

<detalhes>
<síntese>outros quadros</síntese>

- [Megatron-DeepSpeed] (https://github.com/microsoft/Megatron-DeepSpeed) - DeepSpeed versão do Megatron-LM da NVIDIA que adiciona suporte adicional para várias funcionalidades, como MoE model training, Curriculum Learning, 3D Parallelism, entre outras.
(https://github.com/pytorch/torchtune) - Uma biblioteca nativo-porro para LLM Afinação.
- [ROLL](https://github.com/alibaba/ROLL) - Uma Biblioteca de Escalamento Eficiente e Amiga do Utilizador para Aprendizagem de Reforço com Modelos de Língua Grandes.
- [verRL](https://github.com/volcengine/verl) - verRL é uma estrutura RL flexível e eficiente para LLMs.
- [NeMo Framework](https://github.com/NVIDIA/NeMo) - Framework de IA Gerativa construído para pesquisadores e desenvolvedores de PyTorch trabalhando em grandes modelos de linguagem (LLMs), modelos multimodais (MMs), reconhecimento automático de fala (ASR), texto para fala (TTS) e visão de computador (CV).
- [Colossal-AI](https://github.com/hpcaitech/ColossalAI) - Tornar os grandes modelos de IA mais baratos, mais rápidos e acessíveis.
- [BMTrain](https://github.com/OpenBMB/BMTrain) - Treinamento eficiente para grandes modelos.
- [Mesh Tensorflow] (https://github.com/tensorflow/mesh) - Mesh Tensor Fluxo: Modelo Paralelismo Tornado mais fácil.
- [maxtext] (https://github.com/AI-Hypercomputer/maxtext) - Um Jax simples, performante e escalável LLM!
- [GPT-NeoX](https://github.com/EleutherAI/gpt-neox) - Uma implementação de modelos de transformadores autorregressivos paralelos em GPUs, baseados na biblioteca DeepSpeed.
- [Transformer Engine] (https://github.com/NVIDIA/TransformerEngine) - Uma biblioteca para acelerar o treinamento do modelo Transformer em GPUs NVIDIA.
- [OpenRLHF](https://github.com/OpenRLHF/OpenRLHF) - Um Framework RLHF de fácil de usar, escalável e de alto desempenho (70B+ PPO Full Tuning & Iterativo DPO & LoRA & RingAttention & RFT).

- [TRL](https://huggingface.co/docs/trl/en/index) - TRL é uma biblioteca completa que oferece um conjunto de ferramentas para treinar modelos de linguagem transformadora com Aprendizagem por Reforço, abrangendo desde a etapa de Ajuste Fino Supervisionado (SFT) até a Modelagem de Recompensa (RM) e a Otimização de Política Proximal (PPO).
- [unslothai](https://github.com/unslothai/unsloth) - Um framework especializado em ajuste eficiente. Na sua página do GitHub, você pode encontrar modelos de ajuste fino prontos para uso para vários LLMs, permitindo que você treine seus próprios dados gratuitamente na nuvem do Google Colab.
- [Axolotl](https://github.com/axolotl-ai-cloud/axolotl) - Framework de código aberto para ajustar e avaliar LLMs. Ele simplifica o processo de experimentação com diferentes configurações de treinamento e torna fácil reproduzir e compartilhar resultados, suportando recursos como LoRA, QLoRA, DeepSpeed, PEFT e configurações multi-GPU.

</detalhes>

# # LLM Inferência

> Referência: [llm-inference-solutions](https://github.com/mani-kantap/llm-inference-solutions)
- [SGLang](https://github.com/sgl-project/sglang) - SGLang é um framework de serviço rápido para modelos de linguagem de grandes dimensões e modelos de linguagem de visão.
- [vLLM](https://github.com/vllm-project/vllm) - Um motor de inferência e serviço eficiente em termos de alta produtividade e memória para LLMs.
- [llama.cpp] (https://github.com/ggerganov/llama.cpp) - inferência LLM em C/C++.
- [ollama] (https://github.com/ollama/ollama) - Comece a trabalhar com Llama 3, Mistral, Gemma e outros modelos de linguagem de grande porte.
- [TGI](https://huggingface.co/docs/text-generation-inference/en/index) - um kit de ferramentas para implantar e servir modelos de línguas grandes (LLMs).
- [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) - Nvidia Framework para LLM Inferência
<detalhes>
<síntese>outras ferramentas de implantação</síntese>

(https://github.com/NVIDIA/FasterTransformer) - NVIDIA Framework for LLM Inference (Transicionado para TensorRT-LLM)
(https://github.com/microsoft/MInference) Para acelerar a inferência de Long-context LLMs, esparso aproximado e dinâmico calcular a atenção, o que reduz a latência de inferência em até 10x para pré-preenchimento em um A100, mantendo a precisão.
- [exllama] (https://github.com/turboderp/exllama) - Uma reescrita mais eficiente em termos de memória da implementação de transformadores HF de Llama para uso com pesos quantizados.
- [FastChat] (https://github.com/lm-sys/FastChat) - Um sistema de serviço LLM multimodelo distribuído com interface web e APIs RESTful compatíveis com OpenAI.

== Ligações externas ==* Página oficial
- [SkyPilot] (https://github.com/skypilot-org/skypilot) - Execute LLMs e trabalhos em lote em qualquer nuvem. Obtenha economia máxima de custos, maior disponibilidade de GPU e execução gerenciada -- tudo com uma interface simples.
- [Haystack](https://haystack.deepset.ai/) - um framework NLP de código aberto que permite que você use LLMs e modelos baseados em transformadores de Hugging Face, OpenAI e Cohere para interagir com seus próprios dados.
- [OpenLLM](https://github.com/bentoml/OpenLLM) - Fine-tune, servir, implantar e monitorar quaisquer LLMs de código aberto na produção. Usado na produção em [BentoML](https://bentoml.com/) para aplicações baseadas em LLMs.
- [DeepSpeed-Mii](https://github.com/microsoft/DeepSpeed-MII) - MII faz inferência de baixa latência e alta produtividade, semelhante ao vLLM alimentado por DeepSpeed.
- [Text-Embeddings-Inference] (https://github.com/huggingface/text-embeddings-inference) - Inference for text-embeddings in Rust, HFOIL Licence.
- [Infinity] (https://github.com/michaelfeil/infinity) - Inferência para incorporação de textos em Python
- [LMDeploy] (https://github.com/InternLM/lmdeploy) - Um quadro de inferência de alta produtividade e baixa latência para LLMs e VLs
- [Liger-Kernel](https://github.com/linkedin/Liger-Kernel) - Eficientes Kernels Triton para treino LLM.
- [prima.cpp](https://github.com/Lizonghang/prime.cpp) - Uma implementação distribuída de lhama.cpp que permite executar LLMs de nível 70B em seus dispositivos diários.
- [deploy-llms-com-ansível](https://github.com/xamey/deploy-llms-com-ansível) - Implantar facilmente qualquer LLM em uma VM com configuração mínima, usando Ansível.

</detalhes>

# # Aplicações LLM
> Referência: [awesome-llm-apps](https://github.com/Shubhamsaboo/awesome-llm-apps)
- [dspy] (https://github.com/stanfordnlp/dspy) - DSPy: O framework para a programação -- não a pedido - modelos de fundação.
(https://github.com/hwchase17/langchain) Uma biblioteca popular Python/JavaScript para sequências de encadeamento de prompts de modelos de linguagem.
- [LlamaIndex](https://github.com/jerryjliu/llama_index) -- Uma biblioteca Python para aumentar aplicativos LLM com dados.

<detalhes>
<síntese>mais aplicações</síntese>

- [MLflow](https://mlflow.org/) - MLflow: Um framework de código aberto para o ciclo de vida de aprendizado de máquina de ponta a ponta, auxiliando desenvolvedores a rastrear experimentos, avaliar modelos/prompts, implantar modelos e adicionar monitoramento com rastreamento.

(https://github.com/Dicklesworthstone/swiss_army_llama) - Conjunto abrangente de ferramentas para trabalhar com LLMs locais para várias tarefas.
- [LiteChain](https://github.com/rogeriochaves/litechain) - Alternativa leve a LangChain para compor LLMs
(https://github.com/jackmpcollins/magentic) - Integrar LLMs como funções Python
- [wechat-chatgpt] (https://github.com/fuergaosi233/wechat-chatgpt) - Usar ChatGPT Em Wechat via Wechaty
- [promptfoo] (https://github.com/typpo/promptfoo) - Teste as suas instruções. Avalie e compare saídas LLM, regressões de captura e melhore a qualidade imediata.
- [Agenta](https://github.com/agenta-ai/agenta) - Facilmente construir, versionar, avaliar e implantar seus aplicativos movidos a LLM.
- [Serge] (https://github.com/serge-chat/serge) - uma interface de chat criada com lhama.cpp para executar modelos Alpaca. Sem chaves API, totalmente auto-anfitrião!
- [Langroid] (https://github.com/langroid/langroid) - Harness LLMs com programação multi-agente
- [Embedchain](https://github.com/embedchain/embedchain) - Framework para criar o ChatGPT como bots sobre seu conjunto de dados.
- [Opik](https://github.com/comet-ml/opik) - Avaliar, testar e enviar aplicações LLM com um conjunto de ferramentas de observação para calibrar saídas de modelos de linguagem em seu ciclo de vida dev e produção.
- [IntelliServer](https://github.com/intelligentnode/IntelliServer) - simplifica a avaliação dos LLMs fornecendo um microserviço unificado para acessar e testar vários modelos de IA.
- [Langchain-Chatchat] (https://github.com/chatchat-space/Langchain-Chatchat) - Ex-langchain-ChatGLM, aplicativo QA baseado em conhecimento local LLM (como ChatGLM) com langchain.
- [Search with Lepton] (https://github.com/leptonai/search_with_lepton) - Construir o seu próprio motor de busca conversacional utilizando menos de 500 linhas de código por [LeptonAI] (https://github.com/leptonai).
- [Robocorp](https://github.com/robocorp/robocorp) - Criar, implantar e operar ações usando Python em qualquer lugar para melhorar seus agentes e assistentes de IA. Baterias incluídas com um extenso conjunto de bibliotecas, ajudantes e loging.
- [Tune Studio] (https://studio.tune.app/)
(https://github.com/nilsherzig/LLocalSearch) - Rodando localmente Websearch usando cadeias LLM

(https://github.com/Portkey-AI/gateway) - O quê? Gateway simplifica solicitações para 100+ modelos de código aberto e fechado com uma API unificada. Ele também está pronto para a produção com suporte para caching, fallbacks, retries, timeouts, loadebalancing, e pode ser desempregada para latência mínima.
- [talkd.ai dialog] (https://github.com/talkdai/dialog) - API simples para implantar qualquer RAG ou LLM que você deseja adicionar plugins.
- [Wllama] (https://github.com/ngxson/wllama) - Ligação WebAssembly para lhama.cpp - Activando inferência LLM in-browser
- [GPUStack] (https://github.com/gputack/gputack) Um gerenciador de cluster GPU de código aberto para executar LLMs
- [MNN-LLM] (https://github.com/alibaba/MNN) -- Um framework de inferência de dispositivos, incluindo LLM Inferência no dispositivo(Telefone móvel/PC/IOT)
- [CAMEL](https://www.camel-ai.org/) - Primeiro LLM Estrutura multi-agente.
- [QA-Pilot](https://github.com/reid41/QA-Pilot) - Um projeto de chat interativo que aproveita Ollama/OpenAI/MistralAI LLMs para compreensão rápida e navegação de repositório de código GitHub ou recursos de arquivos compactados.
- [Shell-Pilot](https://github.com/reid41/shell-pilot) - Interaja com LLM usando modelos Ollama(ou openAI, mistralAI) através de scripts shell puros em seu sistema Linux(ou MacOS), melhorando o gerenciamento inteligente do sistema sem quaisquer dependências.
- [MindSQL] (https://github.com/Mindinventory/MindSQL) - Um pacote python para Txt-to-SQL com funcionalidades de hospedagem automática e APIs RESTful compatíveis com proprietário, bem como código aberto LLM.
(https://github.com/langfuse/langfuse) - Open Source LLM Engineering Platform - Rastreamento, Avaliações, Gestão de Prompts, Avaliações e Playground.
- [AdalFlow](https://github.com/Sylphai-Inc/AdalFlow) - AdalFlow: A biblioteca para construir & auto-optimizar aplicações LLM.
- [Guidance] (https://github.com/microsoft/guidance) - O quê? Uma biblioteca Python acessível da Microsoft que usa a Templating Handlebars para interlease generation, prompting e controle lógico.
- [Evidentemente] (https://github.com/evidentlyai/evidently) - O quê? Uma estrutura de código aberto para avaliar, testar e monitorar sistemas com ML e LLM.
(https://docs.chainlit.io/overview) -- Uma biblioteca Python para fazer interfaces chatbot.
- [Guardrails.ai] - O quê? Uma biblioteca em Python para validar saídas e tentar falhas novamente. Ainda em alfa, então espere bordas afiadas e bugs.

- [Kernel Semantic] (https://github.com/microsoft/semantic-kernel) -- Uma biblioteca Python/C#/Java da Microsoft que suporta templating rápido, encadeamento de funções, memória vetorializada e planejamento inteligente.
(https://github.com/hegelai/prompttools) - O quê? Ferramentas Python de código aberto para testar e avaliar modelos, DBs vetoriais e prompts.
(https://github.com/normal-computing/outlines) Uma biblioteca Python que fornece uma linguagem específica de domínio para simplificar a geração de pedidos e restrições.
- [Promptify] (https://github.com/promptslab/Promptify) - O quê? Uma pequena biblioteca Python para usar modelos de linguagem para executar tarefas NLP.
- [Scale Spellbook] (https://scale.com/spellbook) Um produto pago para construir, comparar e enviar aplicativos de modelos de linguagem.
(https://promptperfect.jina.ai/prompts) - O quê? Um produto pago para testar e melhorar alertas.
(https://wandb.ai/site/solutions/llmops) - O quê? Um produto pago para treinamento de modelo de rastreamento e experimentos de engenharia rápida.
(https://github.com/openai/evals) - O quê? Uma biblioteca de código aberto para avaliar o desempenho de tarefas de modelos de linguagem e prompts.

(https://www.arthur.ai/get-started) - O quê? Um produto pago para detectar toxicidade, alucinações, injecção rápida, etc.
- [LMQL] (https://lmql.ai) - O quê? Uma linguagem de programação para a interação LLM com suporte para a solicitação digitada, fluxo de controle, restrições e ferramentas.
- [ModeloFusion] (https://github.com/lgramel/modelfusion) - Uma biblioteca TypeScript para a construção de aplicações com LLMs e outros modelos ML (speech-to-text, text-to-speech, image generation).
- [OneKE] (https://openspg.yuque.com/ndx6g9/ps5q6b/vfoi61ks3mqwygvy) - O quê? Um modelo bilíngue de extração de conhecimento chinês-inglês com gráficos de conhecimento e tecnologias de processamento de linguagem natural.
- [llm-ui](https://github.com/llm-ui-kit/llm-ui) - Uma biblioteca React para a construção de UIs LLM.
- [Wordware](https://www.wordware.ai) - Um IDE hospedado na web onde especialistas em domínios não técnicos trabalham com engenheiros de IA para criar agentes de IA específicos para tarefas. Abordamos como uma nova linguagem de programação ao invés de blocos de baixo/sem código.
- [Wallaroo.AI](https://github.com/WallarooLabs) - Implantar, gerenciar, otimizar qualquer modelo em escala através de qualquer ambiente de nuvem para borda. Vamos do caderno de python para a inferência em minutos.

- [Dify](https://github.com/langgenius/dify) - Uma plataforma de desenvolvimento de aplicativos LLM de código aberto com uma interface intuitiva que simplifica fluxos de trabalho de IA, gerenciamento de modelos e implantação em produção.
- [LazyLLM](https://github.com/LazyAGI/LazyLLM) - Uma aplicação LLM de código aberto para a construção de aplicações LLMs multi-agentes de forma fácil e preguiçosa, que suporta a implantação de modelos e ajuste fino.
- [MemFree](https://github.com/memfreeme/memfree) - Motor de busca híbrido de IA de código aberto, que permite obter respostas precisas da Internet, além de marcadores, notas e documentos. Suporte à implantação com um clique.
- [AutoRAG](https://github.com/Marker-Inc-Corea/AutoRAG) - Ferramenta AutoML de código aberto para RAG. Otimize automaticamente a qualidade da resposta RAG, da avaliação de geração de dataset à implantação de pipeline RAG otimizado.
- [epsilla-cloud](https://github.com/epsilla-cloud) - Uma plataforma LLM tudo-em-um para agentes com seus dados e conhecimentos privados, oferecendo agentes de IA prontos para a produção desde o primeiro dia.
- [Arize-Phoenix](https://phoenix.arize.com/) - Ferramenta de código aberto para observação ML que funciona em seu ambiente de notebook. Monitore e ajuste modelos LLM, CV e Tabular.
- [LLM](https://github.com/Hannibal046/Awesome-LLM/blob/main/[https:/github.com/simonw/llm) - Um utilitário CLI e biblioteca Python para interagir com modelos de linguagem grandes, tanto através de APIs remotas quanto com modelos que podem ser instalados e executados em sua própria máquina.
- [Just-Chat](https://github.com/longevity-genie/just-chat) - Crie seu agente LLM e converse com ele de forma simples e rápida!
- [Agentic Radar](https://github.com/splx-ai/agentic-radar) - Scanner de segurança CLI de código aberto para fluxos de trabalho. Verifica o código-fonte do seu fluxo de trabalho, detecta vulnerabilidades e gera uma visualização interativa juntamente com um relatório de segurança detalhado. Suporta LangGraph, CrewAI, n8n, OpenAI Agentes e muito mais.
- [LangWatch](https://github.com/langwatch/langwatch) - Observabilidade LLM de código aberto, com evaporação rápida e uma plataforma de otimização ágil.
- [TensorZero](https://www.tensorzero.com/) - TensorZero é uma estrutura de código aberto para a construção de aplicações LLM de produção. Unifica um gateway LLM, observação, otimização, avaliações e experimentação.

</detalhes>

# # Tutoriais LLM e Cursos
O meu favorito!
- [Umar Jamil Series](https://www.youtube.com/@umarjamilai) - vídeos de alta qualidade e educacional que você não quer perder.

- [Alexander Rush Series](https://rush-nlp.com/projects/) - materiais educativos de alta qualidade que não quer perder.
- [llm-course](https://github.com/mlabonne/llm-course) - Curso para entrar em modelos de línguas grandes (LMLs) com roteiros e cadernos de notas de Colab.
- [UWaterloo CS 886](https://cs.uwaterloo.ca/~wenhuche/ensino/cs886/) - Avanços recentes sobre modelos de fundação.
- [CS25-Transformers United](https://web.stanford.edu/class/cs25/)
- [ChatGPT Prompt Engineering](https://www.deeplearning.ai/curses curtos/chatgpt-prompt-engineering-for-developers/)
- [Princeton: Compreendendo Modelos de Línguas Grandes](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/)
- [CS324 - Modelos de línguas grandes](https://stanford-cs324.github.io/winter2022/)
- [Estado do GPT](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2)
- [A Visual Guide to Mamba and State Space Models] (https://maartengorendorst.substack.com/p/a-visual-guide-to-mamba-and-state?utm_source=multiple-personal-recomendations-email&utm_medium=email&open=false)
- [Vamos construir GPT: do zero, em código, soletrado.](https://www.youtube.com/watch?v=kCc8FmEb1nY)
- [minbpe](https://www.youtube.com/watch?v=zduSFxRajkE&t=1157s) - Código mínimo, limpo para o algoritmo Byte Pair Coding (BPE) comumente usado na tokenização LLM.
- [femtoGPT](https://github.com/keyvank/femtoGPT) - Implementação de Rust Pura de um Transformador Pré-treinado Generativo mínimo.
- [Neurips2022-Fundacional Robustness of Foundation Models (https://nips.cc/virtual/2022/tutorial/55796)
- [ICML2022-Bem-vindo à Era do "Grande Modelo": Técnicas e Sistemas para Treinar e Servir Modelos Maiores](https://icml.cc/virtual/2022/tutorial/18440)
- [GPT em 60 linhas de NumPy] (https://jaykmody.com/blog/gpt-from-scratch/)
- [LLM-RL-Visualized (EN)] (https://github.com/changyeyu/LLM-RL-Visualized/blob/master/src/README_EN.md) (LLM-RL-Visualized (中文)] (https://github.com/changyeyu/LLM-RL-Visualized) - 100+ LLM/RLgorithm Maps.

# # LLM Books
- [I.A. Gerativa com LangChain: Construir aplicativos de grande linguagem (LLM) com Python, ChatGPT e outros LLMs](https://amzn.to/3GULRng) - ele vem com um repositório [GitHub](https://github.com/benman1/generative_ai_with_langchain) que mostra muita funcionalidade
(https://www.manning.com/books/build-a-large-large-language-model-of-scratch) - Um guia para construir a sua própria LLM.

- [BUILD GPT: How AI Works] (https://www.amazon.com/dp/9152799727?ref_=cm_sw_r_cp_ud_dp_W3ZHCD6QWM3DPPC0ARTT_1) - explica como codificar um Transformador Gerativo Pré-treinado, ou GPT, do zero.
- [Mãos-na língua grande Modelos: Entendimento e Geração de Linguagens(https://www.llm-book.com/) - Explore o mundo dos Modelos de Linguagem Grandes com mais de 275 figuras personalizadas neste guia ilustrado!
- [O Livro Chinês para Modelos de Línguas Grandes] (http://aibox.ruc.edu.cn/zws/index.htm) - Um livro introdutório LLM baseado em [* Um levantamento de grandes modelos de linguagem*](https://arxiv.org/abs/2303.18223).

## # Grandes pensamentos sobre LLM
- [Por que toda a reprodução pública do GPT-3 falhou?](https://jingfengyang.github.io/gpt)
- [A Stage Review of Instruction Tuning](https://yaofu.notion.site/Junho-2023-A-Stage-Review-of-Instruction-Tuning-f59dbfc36e2d4e12a33443bd6b2012c2)
(https://lilianweng.github.io/posts/2023-06-23-agent/)
- [Por que você deve trabalhar em AI AGENTS!](https://www.youtube.com/watch?v=fqVLjtvWgq8)
- [Google "Nós não temos nenhum fosso, e nem OpenAI"](https://www.semianalysis.com/p/google-we-have-no-moat-and-new)
(https://petergabriel.com/news/ai-competition-statement/)
- [Prompt Engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engenharia/)
- [Noam Chomsky: A Falsa Promessa do ChatGPT](https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html)
- [ ChatGPT 175 Bilhões de Parâmetros? Análise Técnica](https://orenleung.super.site/is-chatgpt-175-bililion-parâmetros-técnica-análise)
(https://www.notion.so/Awesome-LLM-40c8aa3f2b444ecc82b79ae8bbd2696b)
(https://research.aimultiple.com/large-lange-model-training/)
- [Como o GPT Obtém a sua Capacidade? Traçando Habilidades Emergentes de Modelos Linguísticos para suas Fontes](https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1)
- [Open Pretreined Transformers](https://www.youtube.com/watch?v=p9IxoSkvZ-M&t=4s)
- [Scaling, emergence, and rationaling in large language models](https://docs.google.com/presentation/d/1EUV7W7X_w0BDrscDhPg7lMGzJCkeaPkGCJ3bN8dluXc/edit?pli=1&resourcekey=0-7Nz5A7y8JozyVrnDtcEKJA#slide=id.g16197112905_0_0_0)

# # Diversos

- [Mente Emergente](https://www.emergentmind.com) - As últimas notícias de IA, com curadoria e explicação do GPT-4.
- [ShareGPT](https://sharegpt.com) - Compartilhe suas conversas mais selvagens do ChatGPT com um clique.
(https://docs.google.com/spreadsheets/d/1bmpDdLZxvTCleLGVPgzoMTQ0iDP2-7v7QziPrzPdHyM/edit#gid=0)
- [500+ Melhores ferramentas de IA](https://vaulted-polonium-23c.notion.site/500-Melhor-AI-Ferramentas-e954b36bf688404ababf74a13f98d126)
- [Cohere Summarize Beta] (https://txt.cohere.ai/summarize-beta/) - Apresentando Cohere Resumir Beta: Um novo ponto final para a sumarização do texto
- [chatgpt-wrapper] (https://github.com/mmabrouk/chatgpt-wrapper) - ChatGPT Wrapper é uma API Python não oficial de código aberto e CLI que permite interagir com ChatGPT.
(https://www.cursor.so) - Escreva, edite e converse sobre seu código com uma poderosa IA.
- [AutoGPT](https://github.com/Significant-Gravitas/Auto-GPT) - uma aplicação experimental de código aberto que mostra as capacidades do modelo de linguagem GPT-4.
- [OpenAGI](https://github.com/agiresearch/OpenAGI) - Quando a LLM se encontra com peritos em domínios.
- [EasyEdit](https://github.com/zjunlp/EasyEdit) Um framework fácil de usar para editar modelos de linguagem grandes.
- [chatgpt-shroud](https://github.com/guyShilo/chatgpt-shroud) - Uma extensão do Chrome para o ChatGPT do OpenAI, melhorando a privacidade do usuário, permitindo fácil esconderijo e desescondimento do histórico de chat. Ideal para privacidade durante as partilhas de ecrã.
- [AI For Developers](https://aifordevelopers.org) - Lista de Ferramentas e Agentes de IA para Desenvolvedores

## # Contribuir

Este é um repositório ativo e suas contribuições são sempre bem-vindas!

Vou manter alguns pedidos de pull abertos se eu não tiver certeza se são incríveis para LLM. Você poderia votar neles adicionando-os?

---

Se tiver alguma dúvida sobre esta lista de opiniões, não hesite em contactar-me chengxin1998@stu.pku.edu.cn.

[^1]: Isto não é um conselho jurídico. Entre em contato com os autores originais dos modelos para mais informações.